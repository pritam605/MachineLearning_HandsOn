{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T05:21:12.124290Z","iopub.execute_input":"2023-10-02T05:21:12.124606Z","iopub.status.idle":"2023-10-02T05:21:12.538078Z","shell.execute_reply.started":"2023-10-02T05:21:12.124581Z","shell.execute_reply":"2023-10-02T05:21:12.536775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing libraries for plotting purpose\nimport matplotlib.pyplot as plt\n%matplotlib inline \nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:21:12.841758Z","iopub.execute_input":"2023-10-02T05:21:12.842926Z","iopub.status.idle":"2023-10-02T05:21:13.661435Z","shell.execute_reply.started":"2023-10-02T05:21:12.842890Z","shell.execute_reply":"2023-10-02T05:21:13.660244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:21:13.744378Z","iopub.execute_input":"2023-10-02T05:21:13.744750Z","iopub.status.idle":"2023-10-02T05:21:13.750107Z","shell.execute_reply.started":"2023-10-02T05:21:13.744720Z","shell.execute_reply":"2023-10-02T05:21:13.748521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:21:14.507835Z","iopub.execute_input":"2023-10-02T05:21:14.508181Z","iopub.status.idle":"2023-10-02T05:21:14.515057Z","shell.execute_reply.started":"2023-10-02T05:21:14.508156Z","shell.execute_reply":"2023-10-02T05:21:14.513853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('../input/adult-census-income/adult.csv',encoding='latin-1')\nprint(df.head(2))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:21:53.239190Z","iopub.execute_input":"2023-10-02T05:21:53.239713Z","iopub.status.idle":"2023-10-02T05:21:53.333296Z","shell.execute_reply.started":"2023-10-02T05:21:53.239675Z","shell.execute_reply":"2023-10-02T05:21:53.331606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Exploratory Data Analysis**","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:22:35.158593Z","iopub.execute_input":"2023-10-02T05:22:35.158977Z","iopub.status.idle":"2023-10-02T05:22:35.166837Z","shell.execute_reply.started":"2023-10-02T05:22:35.158949Z","shell.execute_reply":"2023-10-02T05:22:35.165552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:22:49.417691Z","iopub.execute_input":"2023-10-02T05:22:49.418173Z","iopub.status.idle":"2023-10-02T05:22:49.438597Z","shell.execute_reply.started":"2023-10-02T05:22:49.418143Z","shell.execute_reply":"2023-10-02T05:22:49.437761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:23:14.981203Z","iopub.execute_input":"2023-10-02T05:23:14.981561Z","iopub.status.idle":"2023-10-02T05:23:15.019810Z","shell.execute_reply.started":"2023-10-02T05:23:14.981531Z","shell.execute_reply":"2023-10-02T05:23:15.018712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary contains No missing values but dataset has ? values hence we need to encode it to NAN accordingly. \ndf[df == '?'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:24:45.167670Z","iopub.execute_input":"2023-10-02T05:24:45.168030Z","iopub.status.idle":"2023-10-02T05:24:45.203427Z","shell.execute_reply.started":"2023-10-02T05:24:45.168004Z","shell.execute_reply":"2023-10-02T05:24:45.202301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:25:34.650789Z","iopub.execute_input":"2023-10-02T05:25:34.651150Z","iopub.status.idle":"2023-10-02T05:25:34.674141Z","shell.execute_reply.started":"2023-10-02T05:25:34.651125Z","shell.execute_reply":"2023-10-02T05:25:34.673134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, the summary shows that the variables - workclass, occupation and native.country contain missing values. All of these variables are categorical data type. So, I will impute the missing values with the most frequent value- the mode.","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:26:28.749160Z","iopub.execute_input":"2023-10-02T05:26:28.749532Z","iopub.status.idle":"2023-10-02T05:26:28.755726Z","shell.execute_reply.started":"2023-10-02T05:26:28.749501Z","shell.execute_reply":"2023-10-02T05:26:28.754571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Imputing missing values with mode**","metadata":{}},{"cell_type":"code","source":"for cols in ['workclass','occupation','native.country']:\n    df.fillna(df[cols].mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:36:46.035077Z","iopub.execute_input":"2023-10-02T05:36:46.035446Z","iopub.status.idle":"2023-10-02T05:36:46.104100Z","shell.execute_reply.started":"2023-10-02T05:36:46.035416Z","shell.execute_reply":"2023-10-02T05:36:46.102850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:41:09.808286Z","iopub.execute_input":"2023-10-02T05:41:09.808696Z","iopub.status.idle":"2023-10-02T05:41:09.833929Z","shell.execute_reply.started":"2023-10-02T05:41:09.808665Z","shell.execute_reply":"2023-10-02T05:41:09.832501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting target variable \nX = df.drop(['income'],axis=1)\ny = df['income']","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:42:28.646586Z","iopub.execute_input":"2023-10-02T05:42:28.646974Z","iopub.status.idle":"2023-10-02T05:42:28.657377Z","shell.execute_reply.started":"2023-10-02T05:42:28.646946Z","shell.execute_reply":"2023-10-02T05:42:28.656576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:42:36.878459Z","iopub.execute_input":"2023-10-02T05:42:36.878818Z","iopub.status.idle":"2023-10-02T05:42:36.897324Z","shell.execute_reply.started":"2023-10-02T05:42:36.878791Z","shell.execute_reply":"2023-10-02T05:42:36.895818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data into separate training and test set\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:43:34.710674Z","iopub.execute_input":"2023-10-02T05:43:34.711052Z","iopub.status.idle":"2023-10-02T05:43:34.860730Z","shell.execute_reply.started":"2023-10-02T05:43:34.711023Z","shell.execute_reply":"2023-10-02T05:43:34.859606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T05:46:01.877664Z","iopub.execute_input":"2023-10-02T05:46:01.878822Z","iopub.status.idle":"2023-10-02T05:46:01.907364Z","shell.execute_reply.started":"2023-10-02T05:46:01.878785Z","shell.execute_reply":"2023-10-02T05:46:01.905990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature Engineering\n#Encode categorical variables\n\nfrom sklearn import preprocessing\n\ncategorical = ['workclass','education','marital.status','occupation','relationship','race','sex','native.country']\nfor feature in categorical:\n    le = preprocessing.LabelEncoder()\n    X_train[feature] = le.fit_transform(X_train[feature])\n    X_test[feature] = le.fit_transform(X_test[feature])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T06:10:23.863159Z","iopub.execute_input":"2023-10-02T06:10:23.863556Z","iopub.status.idle":"2023-10-02T06:10:23.886121Z","shell.execute_reply.started":"2023-10-02T06:10:23.863525Z","shell.execute_reply":"2023-10-02T06:10:23.884987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature scaling\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\nX_test = pd.DataFrame(scaler.fit_transform(X_test), columns = X.columns )","metadata":{"execution":{"iopub.status.busy":"2023-10-02T06:10:55.251781Z","iopub.execute_input":"2023-10-02T06:10:55.252158Z","iopub.status.idle":"2023-10-02T06:10:55.277746Z","shell.execute_reply.started":"2023-10-02T06:10:55.252129Z","shell.execute_reply":"2023-10-02T06:10:55.276542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T06:11:11.685285Z","iopub.execute_input":"2023-10-02T06:11:11.685774Z","iopub.status.idle":"2023-10-02T06:11:11.710784Z","shell.execute_reply.started":"2023-10-02T06:11:11.685734Z","shell.execute_reply":"2023-10-02T06:11:11.709347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression model with all features ","metadata":{"execution":{"iopub.status.busy":"2023-10-02T06:11:55.519370Z","iopub.execute_input":"2023-10-02T06:11:55.519733Z","iopub.status.idle":"2023-10-02T06:11:55.523851Z","shell.execute_reply.started":"2023-10-02T06:11:55.519706Z","shell.execute_reply":"2023-10-02T06:11:55.523033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlogReg = LogisticRegression()\nlogReg.fit(X_train, y_train)\n\ny_pred = logReg.predict(X_test)\nprint('Logistic Regression accuracy score with all the features : {0:0.04f}'.format(accuracy_score(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2023-10-02T06:16:09.134589Z","iopub.execute_input":"2023-10-02T06:16:09.135483Z","iopub.status.idle":"2023-10-02T06:16:09.295532Z","shell.execute_reply.started":"2023-10-02T06:16:09.135449Z","shell.execute_reply":"2023-10-02T06:16:09.293794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}